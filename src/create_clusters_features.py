# create_clusters_features.py
#
# Name: Laura Tung
#
# Usage: python create_clusters_features.py <final_clusters_sizes> <mode> <n_cores>
#
# <final_clusters_sizes>: the clusters sizes file generated by sort_clusters_reads.py: final_clusters_sizes
# <mode>: "top": create features for top max_spoa_size reads in a cluster;
#         "rest": create features for the rest of reads after top max_spoa_size reads in a cluster;
#         "all": create features for all reads in a cluster (top + rest).


#import pdb; pdb.set_trace() # Uncomment to debug code using pdb (like gdb)

import sys
import numpy as np
import pandas as pd

import subprocess
import multiprocessing
import time


def create_features_one_cluster(fail_list, cluster_id, cluster_size, mode, bin_dir, max_spoa_size):  
    
    print("Cluster", cluster_id)
    
    try:
        if cluster_size <= max_spoa_size:
            if (mode == "top") or (mode == "all"):
                spoa_set_fastq = str(cluster_id) + ".fixed.fastq"
                outdir = str(cluster_id) + ".spoa_output"
                spoa_out_fasta = str(cluster_id) + ".spoa_sma_output.fa"
                
                subprocess.call(bin_dir + "run.spoa_default.sh " + spoa_set_fastq + " " + outdir + " " + spoa_out_fasta, shell=True)
                
                msa_spoa_file = outdir + "/" + spoa_out_fasta
                subprocess.call("python3.6 " + bin_dir + "process_msa_spoa.py " + msa_spoa_file + " " + spoa_set_fastq + " " + "set", shell=True)
            
        else:
            if (mode == "top") or (mode == "all"):
                # process top max_spoa_size reads in the cluster
                spoa_set_fastq = str(cluster_id) + ".top.fixed.fastq"
                outdir = str(cluster_id) + ".top.spoa_output"
                spoa_out_fasta = str(cluster_id) + ".top.spoa_sma_output.fa"
                
                subprocess.call(bin_dir + "run.spoa_default.sh " + spoa_set_fastq + " " + outdir + " " + spoa_out_fasta, shell=True)
                
                msa_spoa_file = outdir + "/" + spoa_out_fasta
                subprocess.call("python3.6 " + bin_dir + "process_msa_spoa.py " + msa_spoa_file + " " + spoa_set_fastq + " " + "set", shell=True)
                
            if (mode == "rest") or (mode == "all"):
                # process the rest of reads after top max_spoa_size reads in the cluster
                rest_dir = str(cluster_id) + ".rest_reads"
                subprocess.call("mkdir -p " + rest_dir, shell=True)
                
                sorted_fixed_file = str(cluster_id) + ".sorted.fixed.fastq"
                top_fastq = str(cluster_id) + ".top.fixed.fastq"
                
                for i in range(max_spoa_size+1, cluster_size+1):
                    print("Read", i)
                    
                    tmp_file = rest_dir + "/" + str(i) + ".tmp.fastq"
                    end_line = i*4
                    subprocess.call("head -" + str(end_line) + " " + sorted_fixed_file + " | tail -4 - > " + tmp_file, shell=True)
                    
                    with open(tmp_file) as f:
                        first_line = f.readline().strip()
                    read_name = first_line[1:].split(' ')[0]
                    
                    spoa_set_fastq = rest_dir + "/" + str(i) + ".spoa_set.fastq"
                    subprocess.call("cat " + top_fastq + " " + tmp_file + " > " + spoa_set_fastq, shell=True)
                    subprocess.call("rm " + tmp_file, shell=True)
                    
                    outdir = rest_dir + "/" + str(i) + ".spoa_output"
                    spoa_out_fasta = str(i) + ".spoa_sma_output.fa"
                    subprocess.call(bin_dir + "run.spoa_default.sh " + spoa_set_fastq + " " + outdir + " " + spoa_out_fasta, shell=True)
                    
                    msa_spoa_file = outdir + "/" + spoa_out_fasta
                    subprocess.call("python3.6 " + bin_dir + "process_msa_spoa.py " + msa_spoa_file + " " + spoa_set_fastq + " '" + read_name + "'", shell=True)
        
                    # remove .spoa_sma_output.fa file and .spoa_set.fastq file to save disk space
                    subprocess.call("rm " + msa_spoa_file, shell=True)
                    subprocess.call("rm " + spoa_set_fastq, shell=True)
        return 0
    except:
        fail_list.append(cluster_id)
        return 1


def create_features_for_clusters(clusters_sizes_array, mode, n_cores, bin_dir, max_spoa_size):
    
    context = multiprocessing.get_context("spawn")
    pool = context.Pool(processes=n_cores)
    manager = multiprocessing.Manager()
    fail_list = manager.list()    
    
    for i in range(clusters_sizes_array.shape[0]):
        cluster_id = clusters_sizes_array[i,0]
        cluster_size = clusters_sizes_array[i,1]
        
        if mode == "rest":
            if cluster_size <= max_spoa_size:
                continue
        
        if n_cores <= 1:
            create_features_one_cluster(fail_list, cluster_id, cluster_size, mode, bin_dir, max_spoa_size)
        else:
            pool.apply_async(create_features_one_cluster, (fail_list, cluster_id, cluster_size, mode, bin_dir, max_spoa_size,))        
    
    pool.close()
    pool.join()

    time.sleep(1)
    if len(fail_list) > 0:
        print('Warning: ' + str(len(fail_list)) + ' clusters features could not be created:')
        print(fail_list)
                
    return None


if __name__ == "__main__":
    
    clusters_sizes_file = sys.argv[1]
    mode = sys.argv[2]
    n_cores = int(sys.argv[3])
    
    bin_dir = "/mnt/disk39/user/ltung/ML_error_correction/bin/"
    max_spoa_size = 800
    
    clusters_sizes_array = np.loadtxt(clusters_sizes_file, dtype='int')
    print("clusters_sizes_array shape:", clusters_sizes_array.shape)
    
    create_features_for_clusters(clusters_sizes_array, mode, n_cores, bin_dir, max_spoa_size)
    
    