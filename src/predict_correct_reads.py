# predict_correct_reads.py
#
# Name: Laura Tung
#
# Usage: python predict_correct_reads.py <fullpath_model_file> <final_clusters_sizes> <fullpath_clusters_fastq_dir> <out_dir> <max_read_length_training>
#
# <fullpath_model_file>: full-path trained model file.
# <final_clusters_sizes>: the clusters sizes file generated by sort_clusters_reads.py: final_clusters_sizes.
# <fullpath_clusters_fastq_dir>: full-path clusters directory that contains the original fastq files and merged features csv files for every cluster.
# <out_dir>: the output directory to save the corrected reads fastq file.
# <max_read_length_training>: the maximum read length in the training+test dataset for the trained model, which is used to normalize read-length feature.
#

import sys
import numpy as np
import pandas as pd

import pickle
import ast
import math

from tensorflow import keras
from keras.models import load_model
from keras.layers import Masking


reverse_label_code = {
        0: 'Insertion',
        1: 'Substituted_A',
        2: 'Substituted_C',
        3: 'Substituted_G',
        4: 'Substituted_T',
        5: 'Deleted_A',
        6: 'Deleted_C',
        7: 'Deleted_G',
        8: 'Deleted_T',
        9: 'No_correction'
    }


def apply_mask_into_1d(label_array, mask):
    
    x = np.ma.array(label_array, mask=~mask)
    unmasked_1d_label_array = x.compressed()
    
    return unmasked_1d_label_array


def get_keras_mask(rest_features_input):
    
    masking_rest_features = Masking(mask_value=-1., input_shape=rest_features_input.shape[1:])(rest_features_input)
    keras_mask = masking_rest_features._keras_mask
    
    return keras_mask.numpy()


def correct_one_read(read_seq, read_qual, unmasked_predicted_labels):
    
    corr_read_seq = ""
    corr_read_qual = ""
    
    for i in range(len(read_seq)):
        pred = reverse_label_code[unmasked_predicted_labels[i]]
        
        if (read_seq[i] == 'A') or (read_seq[i] == 'C') or (read_seq[i] == 'G') or (read_seq[i] == 'T'):
            if pred == 'No_correction':
                corr_read_seq += read_seq[i]
                corr_read_qual += chr(read_qual[i]+33)
            elif pred == 'Insertion':
                continue
            elif (pred == 'Substituted_A') or (pred == 'Substituted_C') or (pred == 'Substituted_G') or (pred == 'Substituted_T'):
                corr_read_seq += pred[-1]
                corr_read_qual += '+'          # use quality score 10 for any corrected bases.
            elif (pred == 'Deleted_A') or (pred == 'Deleted_C') or (pred == 'Deleted_G') or (pred == 'Deleted_T'):
                # insert “X” in front of the read letter
                corr_read_seq += pred[-1] + read_seq[i]
                corr_read_qual += '+' + chr(read_qual[i]+33)
            
        elif read_seq[i] == '-':
            if pred == 'No_correction':
                continue
            elif pred == 'Insertion':
                continue
            elif (pred == 'Substituted_A') or (pred == 'Substituted_C') or (pred == 'Substituted_G') or (pred == 'Substituted_T'):
                # replace the "-" with “X”
                corr_read_seq += pred[-1]
                corr_read_qual += '+'
            elif (pred == 'Deleted_A') or (pred == 'Deleted_C') or (pred == 'Deleted_G') or (pred == 'Deleted_T'):
                corr_read_seq += pred[-1]
                corr_read_qual += '+'
    
    return corr_read_seq, corr_read_qual


def correct_reads_one_cluster(cluster_id, model, clusters_fastq_dir, out_dir, max_read_length):
    
    print("Cluster", cluster_id)
    
    predict_dir = str(cluster_id) + ".prediction"
    
    left_kmers_input_file = predict_dir + "/left_kmers_input.npy"
    right_kmers_input_file = predict_dir + "/right_kmers_input.npy"
    read_features_input_file = predict_dir + "/read_features_input.npy"
    consensus_features_input_file = predict_dir + "/consensus_features_input.npy"
    rest_features_input_file = predict_dir + "/rest_features_input.npy"
    
    left_kmers_input = np.load(left_kmers_input_file)
    right_kmers_input = np.load(right_kmers_input_file)
    read_features_input = np.load(read_features_input_file)
    consensus_features_input = np.load(consensus_features_input_file)
    rest_features_input = np.load(rest_features_input_file)
    print("left_kmers_input shape:", left_kmers_input.shape)
    print("right_kmers_input shape:", right_kmers_input.shape)
    print("read_features_input shape:", read_features_input.shape)
    print("consensus_features_input shape:", consensus_features_input.shape)
    print("rest_features_input shape:", rest_features_input.shape)
    
    pickle_in = open(predict_dir + "/read_rows_dict.pickle","rb")
    read_rows_dict = pickle.load(pickle_in)
    pickle_in.close()
    
    features_csv = str(cluster_id) + ".spoa_sma_output_features.csv"
    merged_df = pd.read_csv(clusters_fastq_dir + "/" + features_csv, sep=',', low_memory=False)
    
    # normalize read_length feature using the max_read_length associated with the model being used.
    # read_length is the first one in the last dimension of the rest_features_input 3D array.
    # also recover the -1 padding after the normalization.
    rest_features_input[:,:,0] = rest_features_input[:,:,0]/max_read_length
    rest_features_input[:,:,0][rest_features_input[:,:,0] < 0] = -1.
    
    # make predictions
    predicted_labels = model.predict([left_kmers_input, right_kmers_input, read_features_input, consensus_features_input, rest_features_input])
    print("predicted_labels shape:", predicted_labels.shape)
    
    # model.predict() returns a numpy array that does not carry ._keras_mask anymore.
    # so we have to manually apply the Masking layer to an input in order to obtain the ._keras_mask
    keras_mask = get_keras_mask(rest_features_input)
    print("keras_mask shape:", keras_mask.shape)
    
    # convert probability predictions to integer class predictions
    integer_predicted_labels = np.argmax(predicted_labels, axis=2)
    print("integer_predicted_labels shape:", integer_predicted_labels.shape) 
    
    # output fastq file
    out_fastq = str(cluster_id) + ".corrected_reads.fastq"
    outfile = open(out_dir + "/" + out_fastq, "w")
    
    # correct each read in the cluster
    for i in range(len(merged_df)):
        read_name = merged_df.loc[i, 'read_name']
        read_seq = ast.literal_eval(merged_df.loc[i, 'read_sequence'])
        read_qual = ast.literal_eval(merged_df.loc[i, 'read_quality'])
    
        read_rows = read_rows_dict[read_name]
        
        # get unmasked predicted labels for this read as 1D
        unmasked_predicted_labels = apply_mask_into_1d(integer_predicted_labels[read_rows], keras_mask[read_rows])
        
        # correct the read
        corr_read_seq, corr_read_qual = correct_one_read(read_seq, read_qual, unmasked_predicted_labels)
        
        # write to the fastq
        outfile.write("@{0}\n{1}\n+\n{2}\n".format(read_name, corr_read_seq, corr_read_qual))
        
    
    outfile.close()
    
    return None
    

def correct_reads_for_clusters(clusters_sizes_array, model_file, clusters_fastq_dir, out_dir, max_read_length):
    
    # load the model
    model = load_model(model_file)

    for i in range(clusters_sizes_array.shape[0]):
        cluster_id = clusters_sizes_array[i,0]
       
        correct_reads_one_cluster(cluster_id, model, clusters_fastq_dir, out_dir, max_read_length)

    return None
    

if __name__ == "__main__":
    
    model_file = sys.argv[1]
    clusters_sizes_file = sys.argv[2]
    clusters_fastq_dir = sys.argv[3]
    out_dir = sys.argv[4]
    max_read_length = int(sys.argv[5])
    
    print("max_read_length used in training/testing the model:", max_read_length)
    
    # get the clusters sizes info
    clusters_sizes_array = np.loadtxt(clusters_sizes_file, dtype='int')
    print("clusters_sizes_array shape:", clusters_sizes_array.shape)
    
    # make predictions and correct reads for clusters
    correct_reads_for_clusters(clusters_sizes_array, model_file, clusters_fastq_dir, out_dir, max_read_length)
    


