# combine_features_labels.py
#
# Name: Laura Tung
#
# Usage: python combine_features_labels.py <pickled_align_labels_dict_file> <final_clusters_sizes>
#
# <pickled_align_labels_dict_file>: the pickled align_labels_dict file: align_labels_dict.pickle
# <final_clusters_sizes>: the clusters sizes file generated by sort_clusters_reads.py: final_clusters_sizes

#import pdb; pdb.set_trace() # Uncomment to debug code using pdb (like gdb)

import sys
import numpy as np
import pandas as pd

import pickle
import ast


def merge_pairwise_alignments(align1_read_seq, align1_consensus_seq, align1_read_qual, align1_consensus_occur_freq, align1_consensus_avg_qual, align2_read_seq, align2_true_read_seq, align2_true_labels):
    
    align1_length = len(align1_read_seq)
    align2_length = len(align2_read_seq)
    
    merged_read_seq = []
    merged_consensus_seq = []
    merged_true_read_seq = []
    
    merged_read_qual = []
    merged_consensus_occur_freq = []
    merged_consensus_avg_qual = []
    
    merged_true_labels = []
    
    i = 0        # index of align1_read_seq
    j = 0        # index of align2_read_seq
    
    while (i < align1_length) and (j < align2_length):
        if align1_read_seq[i] == align2_read_seq[j]:
            merged_read_seq.append(align1_read_seq[i])
            merged_consensus_seq.append(align1_consensus_seq[i])
            merged_true_read_seq.append(align2_true_read_seq[j])
            
            merged_read_qual.append(align1_read_qual[i])
            merged_consensus_occur_freq.append(align1_consensus_occur_freq[i])
            merged_consensus_avg_qual.append(align1_consensus_avg_qual[i])
            
            merged_true_labels.append(align2_true_labels[j])
            
            i += 1
            j += 1
        elif (align1_read_seq[i] == "-") and (align2_read_seq[j] != "-"):
            merged_read_seq.append("-")
            merged_consensus_seq.append(align1_consensus_seq[i])
            merged_true_read_seq.append("-")
            
            merged_read_qual.append(align1_read_qual[i])
            merged_consensus_occur_freq.append(align1_consensus_occur_freq[i])
            merged_consensus_avg_qual.append(align1_consensus_avg_qual[i])
            
            merged_true_labels.append("No_correction")
            
            i += 1
        elif (align1_read_seq[i] != "-") and (align2_read_seq[j] == "-"):
            merged_read_seq.append("-")
            merged_consensus_seq.append("-")
            merged_true_read_seq.append(align2_true_read_seq[j])
            
            merged_read_qual.append(0)
            merged_consensus_occur_freq.append(0.0)
            merged_consensus_avg_qual.append(0.0)
            
            merged_true_labels.append(align2_true_labels[j])
            
            j += 1
            
    while i < align1_length:
        merged_read_seq.append(align1_read_seq[i])
        merged_consensus_seq.append(align1_consensus_seq[i])
        merged_true_read_seq.append("-")
        
        merged_read_qual.append(align1_read_qual[i])
        merged_consensus_occur_freq.append(align1_consensus_occur_freq[i])
        merged_consensus_avg_qual.append(align1_consensus_avg_qual[i])    
        
        merged_true_labels.append("No_correction")
        
        i += 1
        
    while j < align2_length:
        merged_read_seq.append(align2_read_seq[j])
        merged_true_read_seq.append(align2_true_read_seq[j])
        merged_consensus_seq.append("-")
        
        merged_read_qual.append(0)
        merged_consensus_occur_freq.append(0.0)
        merged_consensus_avg_qual.append(0.0)        
        
        merged_true_labels.append(align2_true_labels[j])
        
        j += 1
        
    return merged_read_seq, merged_consensus_seq, merged_true_read_seq, merged_read_qual, merged_consensus_occur_freq, merged_consensus_avg_qual, merged_true_labels 


def combine_features_labels_one_cluster(fail_list, align_labels_dict, cluster_id, cluster_size, max_spoa_size):
    
    print("Cluster", cluster_id)
    
    if cluster_size <= max_spoa_size:
        outdir = str(cluster_id) + ".spoa_output"
        features_file = outdir + "/" + str(cluster_id) + ".spoa_sma_output_features.csv"
    else:
        outdir = str(cluster_id) + ".top.spoa_output"
        features_file = outdir + "/" + str(cluster_id) + ".top.spoa_sma_output_features.csv"
        
    features_df = pd.read_csv(features_file, sep=',', low_memory=False)
    
    data_list = []
    
    for i in range(len(features_df)):
        read_name = features_df["read_name"][i]
        
        try:
            value = align_labels_dict[read_name]           
        except KeyError:
            fail_list.append(read_name)
            continue
        
        align1_read_seq = ast.literal_eval(features_df["read_sequence"][i])
        align1_consensus_seq = ast.literal_eval(features_df["consensus_sequence"][i])
        align1_read_qual = ast.literal_eval(features_df["read_quality"][i])
        align1_consensus_occur_freq = ast.literal_eval(features_df["consensus_occur_frequency"][i])
        align1_consensus_avg_qual = ast.literal_eval(features_df["consensus_avg_quality"][i])
        
        align2_read_seq = value[0]
        align2_true_read_seq = value[1]
        align2_true_labels = value[2]
        
        merged_read_seq, merged_consensus_seq, merged_true_read_seq, merged_read_qual, merged_consensus_occur_freq, merged_consensus_avg_qual, merged_true_labels = \
        merge_pairwise_alignments(align1_read_seq, align1_consensus_seq, align1_read_qual, align1_consensus_occur_freq, align1_consensus_avg_qual, align2_read_seq, align2_true_read_seq, align2_true_labels) 
        
        data_list.append([read_name, merged_read_seq, merged_read_qual, merged_consensus_seq, merged_consensus_occur_freq, merged_consensus_avg_qual, features_df["read_length"][i], features_df["GC_content"][i], features_df["number_spoa_reads"][i], features_df["strand"][i], merged_true_labels, merged_true_read_seq])
    
    data_df = pd.DataFrame(data_list, columns = ["read_name", "read_sequence", "read_quality", "consensus_sequence", "consensus_occur_frequency", "consensus_avg_quality", "read_length", "GC_content", "number_spoa_reads", "strand", "true_labels", "true_read_sequence"])
    
    pd.DataFrame.to_csv(data_df, path_or_buf=features_file[:-4] + "_labels.csv", index=False)
    
    return None


def combine_features_labels_for_clusters(clusters_sizes_array, max_spoa_size, align_labels_dict):
    
    fail_list = [] 
    
    for i in range(clusters_sizes_array.shape[0]):
        cluster_id = clusters_sizes_array[i,0]
        cluster_size = clusters_sizes_array[i,1]
                
        combine_features_labels_one_cluster(fail_list, align_labels_dict, cluster_id, cluster_size, max_spoa_size)
        
    if len(fail_list) > 0:
        print('Warning: ' + str(len(fail_list)) + ' reads have no true labels (unaligned to the genome or chimeric alignment):')
        print(fail_list)
                
    return None
    
        
if __name__ == "__main__":

    pickled_align_labels_dict_file = sys.argv[1]
    clusters_sizes_file = sys.argv[2]
    
    max_spoa_size = 800
    
    # load the pickled alignment-labels dictionary
    pickle_in = open(pickled_align_labels_dict_file,"rb")
    align_labels_dict = pickle.load(pickle_in)
    pickle_in.close()
    
    print("align_labels_dict size:", len(align_labels_dict))
    
    # get the clusters sizes info
    clusters_sizes_array = np.loadtxt(clusters_sizes_file, dtype='int')
    print("clusters_sizes_array shape:", clusters_sizes_array.shape)
    
    combine_features_labels_for_clusters(clusters_sizes_array, max_spoa_size, align_labels_dict)
    
    
   
    
